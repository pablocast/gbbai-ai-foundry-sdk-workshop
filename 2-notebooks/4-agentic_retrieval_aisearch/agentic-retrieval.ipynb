{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eafbcdde",
   "metadata": {},
   "source": [
    "## Agentic retrieval in Azure AI Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91cb4ff",
   "metadata": {},
   "source": [
    "Use this notebook to get started with agentic retrieval in Azure AI Search, which integrates conversation history and large language models (LLMs) on Azure OpenAI to plan, retrieve, and synthesize complex queries.\n",
    "\n",
    "Steps in this notebook include:\n",
    "\n",
    "+ Creating an `product` search index.\n",
    "\n",
    "+ Loading the index with outdoor product from [manuals](./manuals).\n",
    "\n",
    "+ Creating an products-search-agent in Azure AI Search that points to an LLM for query planning.\n",
    "\n",
    "Generating answers using the Azure OpenAI client."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8fbe07",
   "metadata": {},
   "source": [
    "## Set up connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e14b0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)  # Take environment variables from .env.\n",
    "\n",
    "answer_model = os.getenv(\"ANSWER_MODEL\", \"gpt-4o\")\n",
    "endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(\n",
    "    credential, \"https://search.azure.com/.default\"\n",
    ")\n",
    "index_name = \"products\"\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_gpt_deployment = os.getenv(\"GENERATIVE_DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "azure_openai_gpt_model = os.getenv(\"GENERATIVE_DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2025-03-01-preview\")\n",
    "azure_openai_embedding_deployment = os.getenv(\n",
    "    \"EMBEDDING_DEPLOYMENT_NAME\", \"text-embedding-3-large\"\n",
    ")\n",
    "azure_openai_embedding_model = os.getenv(\n",
    "    \"EMBEDDING_DEPLOYMENT_NAME\", \"text-embedding-3-large\"\n",
    ")\n",
    "agent_name = \"products-search-agent\"\n",
    "api_version = \"2025-05-01-Preview\"\n",
    "storage_account_url = os.environ[\"AZURE_STORAGE_ACCOUNT_URL\"]\n",
    "blob_source = \"sample-docs-container\"\n",
    "blob_artifacts = \"knowledgestore-artifacts\"\n",
    "local_data_source = \"manuals\"\n",
    "subscription_id = os.environ[\"AZURE_SUBSCRIPTION_ID\"]\n",
    "resource_group = os.environ[\"AZURE_RESOURCE_GROUP\"]\n",
    "storage_account_name = os.environ[\"AZURE_STORAGE_ACCOUNT_NAME\"]\n",
    "azure_aiservices_endpoint = os.environ[\"AZURE_AI_SERVICES_ENDPOINT\"]\n",
    "azure_openai_embeddings_dimensions = 3072"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2b660",
   "metadata": {},
   "source": [
    "## Create an index in Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a6ed9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weight is not a known attribute of class <class 'azure.search.documents.indexes._generated.models._models_py3.SemanticField'> and will be ignored\n",
      "weight is not a known attribute of class <class 'azure.search.documents.indexes._generated.models._models_py3.SemanticField'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'products' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SemanticSearch,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    ComplexField,\n",
    "    HnswParameters,\n",
    ")\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "fields = [\n",
    "    SearchableField(\n",
    "        name=\"content_id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        analyzer_name=\"keyword\",\n",
    "    ),\n",
    "    SimpleField(\n",
    "        name=\"text_document_id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=False,\n",
    "        filterable=True,\n",
    "        hidden=False,\n",
    "        sortable=False,\n",
    "        facetable=False,\n",
    "    ),\n",
    "    SimpleField(\n",
    "        name=\"image_document_id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=False,\n",
    "        filterable=True,\n",
    "        hidden=False,\n",
    "        sortable=False,\n",
    "        facetable=False,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"document_title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "        filterable=True,\n",
    "        hidden=False,\n",
    "        sortable=True,\n",
    "        facetable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"content_text\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "        filterable=True,\n",
    "        hidden=False,\n",
    "        sortable=True,\n",
    "        facetable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content_embedding\",\n",
    "        hidden=False,\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        vector_search_dimensions=1536,\n",
    "        searchable=True,\n",
    "        vector_search_profile_name=f\"{index_name}-profile\",\n",
    "    ),\n",
    "    SimpleField(\n",
    "        name=\"content_path\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=False,\n",
    "        filterable=True,\n",
    "        hidden=False,\n",
    "        sortable=False,\n",
    "        facetable=False,\n",
    "    ),\n",
    "    ComplexField(\n",
    "        name=\"locationMetadata\",\n",
    "        fields=[\n",
    "            SimpleField(\n",
    "                name=\"pageNumber\",\n",
    "                type=SearchFieldDataType.Int32,\n",
    "                searchable=False,\n",
    "                filterable=True,\n",
    "                hidden=False,\n",
    "                sortable=True,\n",
    "                facetable=True,\n",
    "            ),\n",
    "            SimpleField(\n",
    "                name=\"boundingPolygons\",\n",
    "                type=SearchFieldDataType.String,\n",
    "                searchable=False,\n",
    "                hidden=False,\n",
    "                filterable=False,\n",
    "                sortable=False,\n",
    "                facetable=False,\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "index = SearchIndex(\n",
    "    fields=fields,\n",
    "    name=index_name,\n",
    "    vector_search=VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=f\"{index_name}-algo\",\n",
    "                parameters=HnswParameters(\n",
    "                    metric=\"cosine\",\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=f\"{index_name}-vectorizer\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=azure_openai_endpoint,\n",
    "                    deployment_name=azure_openai_embedding_deployment,\n",
    "                    model_name=azure_openai_embedding_model,\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                algorithm_configuration_name=f\"{index_name}-algo\",\n",
    "                vectorizer_name=f\"{index_name}-vectorizer\",\n",
    "                name=f\"{index_name}-profile\",\n",
    "            )\n",
    "        ],\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semanticconfig\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semanticconfig\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    title_field=SemanticField(\n",
    "                        field_name=\"document_title\",\n",
    "                        weight=1.0,\n",
    "                    ),\n",
    "                    content_fields=[\n",
    "                        SemanticField(\n",
    "                            field_name=\"content_text\",\n",
    "                            weight=1.0,\n",
    "                        )\n",
    "                    ],\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"Index '{index_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf85d9",
   "metadata": {},
   "source": [
    "## Create a datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a40ebb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.core.pipeline.policies import UserAgentPolicy\n",
    "USER_AGENT = \"ai-search-multimodal-sample/1.0.0\"\n",
    "\n",
    "indexer_client = SearchIndexerClient(\n",
    "    endpoint=endpoint, \n",
    "    credential=credential,\n",
    "    user_agent_policy=UserAgentPolicy(base_user_agent=USER_AGENT)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cac31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x000001C75DB89490>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating container: The specified container already exists.\n",
      "RequestId:345cb086-101e-0015-2c59-cf070a000000\n",
      "Time:2025-05-27T22:46:07.1846512Z\n",
      "ErrorCode:ContainerAlreadyExists\n",
      "Content: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>ContainerAlreadyExists</Code><Message>The specified container already exists.\n",
      "RequestId:345cb086-101e-0015-2c59-cf070a000000\n",
      "Time:2025-05-27T22:46:07.1846512Z</Message></Error>\n",
      "Data source connection 'products-blob' created successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob.aio import BlobServiceClient\n",
    "import glob\n",
    "import aiofiles\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerDataSourceType,\n",
    "    NativeBlobSoftDeleteDeletionDetectionPolicy,\n",
    ")\n",
    "import os\n",
    "\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url=storage_account_url,\n",
    "    credential=credential,\n",
    ")\n",
    "\n",
    "container_client = blob_service_client.get_container_client(blob_source)\n",
    "try:\n",
    "    await container_client.create_container()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating container: {e}\")\n",
    "\n",
    "document_paths = glob.glob(os.path.join(os.getcwd(), local_data_source, \"*.*\"))\n",
    "print(f\"Document paths: {document_paths}\")\n",
    "for doc_path in document_paths:\n",
    "    print(f\"Uploading file: {doc_path}\")\n",
    "    async with aiofiles.open(doc_path, \"rb\") as f:\n",
    "        file_bytes = await f.read()\n",
    "        file_name = os.path.basename(doc_path)\n",
    "        await container_client.upload_blob(file_name, file_bytes, overwrite=True)\n",
    "\n",
    "ds_container = SearchIndexerDataContainer(name=blob_source)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=SearchIndexerDataSourceType.AZURE_BLOB,\n",
    "    connection_string=f\"ResourceId=/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.Storage/storageAccounts/{storage_account_name};\",\n",
    "    container=ds_container,\n",
    "    data_deletion_detection_policy=NativeBlobSoftDeleteDeletionDetectionPolicy(),\n",
    ")\n",
    "\n",
    "indexer_client.create_data_source_connection(\n",
    "        data_source_connection\n",
    ")\n",
    "\n",
    "print(f\"Data source connection '{data_source_connection.name}' created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d5afc8",
   "metadata": {},
   "source": [
    "## Create Skillset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f45f7ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    DocumentIntelligenceLayoutSkill,\n",
    "    ShaperSkill,\n",
    "    ChatCompletionSkill,\n",
    "    DocumentIntelligenceLayoutSkillChunkingProperties,\n",
    ")\n",
    "from datetime import timedelta\n",
    "\n",
    "# Create document intelligence layout skill\n",
    "document_layout_skill = DocumentIntelligenceLayoutSkill(\n",
    "    name=\"document-cracking-skill\",\n",
    "    description=\"Document Intelligence skill for document cracking\",\n",
    "    context=\"/document\",\n",
    "    output_mode=\"oneToMany\",\n",
    "    output_format=\"text\",\n",
    "    extraction_options=[\"images\", \"locationMetadata\"],\n",
    "    markdown_header_depth=\"\",\n",
    "    chunking_properties=DocumentIntelligenceLayoutSkillChunkingProperties(\n",
    "        unit=\"characters\",\n",
    "        maximum_length=2000,\n",
    "        overlap_length=200,\n",
    "    ),\n",
    "    inputs=[InputFieldMappingEntry(name=\"file_data\", source=\"/document/file_data\")],\n",
    "    outputs=[\n",
    "        OutputFieldMappingEntry(name=\"text_sections\", target_name=\"text_sections\"),\n",
    "        OutputFieldMappingEntry(\n",
    "            name=\"normalized_images\", target_name=\"normalized_images\"\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create Azure OpenAI embedding skill\n",
    "azure_embedding_skill = AzureOpenAIEmbeddingSkill(\n",
    "    name=\"text-embedding-skill\",\n",
    "    context=\"/document/text_sections/*\",\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/text_sections/*/content\")\n",
    "    ],\n",
    "    outputs=[OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\")],\n",
    "    resource_url=azure_openai_endpoint,\n",
    "    deployment_name=azure_openai_embedding_deployment,\n",
    "    dimensions=azure_openai_embeddings_dimensions,\n",
    "    model_name=azure_openai_embedding_deployment,\n",
    ")\n",
    "\n",
    "# Create gpt skill\n",
    "gpt_skill = ChatCompletionSkill(\n",
    "    name=\"chat-completion-skill\",\n",
    "    uri=f\"{azure_openai_endpoint}/openai/deployments/gpt-4.1/chat/completions?api-version=2024-10-21\",\n",
    "    timeout=timedelta(minutes=1),\n",
    "    context=\"/document/normalized_images/*\",\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(\n",
    "            name=\"systemMessage\",\n",
    "            source='=\\'You are tasked with generating concise, accurate descriptions of images, figures, diagrams, or charts in documents. The goal is to capture the key information and meaning conveyed by the image without including extraneous details like style, colors, visual aesthetics, or size.\\n\\nInstructions:\\nContent Focus: Describe the core content and relationships depicted in the image.\\n\\nFor diagrams, specify the main elements and how they are connected or interact.\\nFor charts, highlight key data points, trends, comparisons, or conclusions.\\nFor figures or technical illustrations, identify the components and their significance.\\nClarity & Precision: Use concise language to ensure clarity and technical accuracy. Avoid subjective or interpretive statements.\\n\\nAvoid Visual Descriptors: Exclude details about:\\n\\nColors, shading, and visual styles.\\nImage size, layout, or decorative elements.\\nFonts, borders, and stylistic embellishments.\\nContext: If relevant, relate the image to the broader content of the technical document or the topic it supports.\\n\\nExample Descriptions:\\nDiagram: \"A flowchart showing the four stages of a machine learning pipeline: data collection, preprocessing, model training, and evaluation, with arrows indicating the sequential flow of tasks.\"\\n\\nChart: \"A bar chart comparing the performance of four algorithms on three datasets, showing that Algorithm A consistently outperforms the others on Dataset 1.\"\\n\\nFigure: \"A labeled diagram illustrating the components of a transformer model, including the encoder, decoder, self-attention mechanism, and feedforward layers.\"\\'',\n",
    "        ),\n",
    "        InputFieldMappingEntry(\n",
    "            name=\"userMessage\",\n",
    "            source=\"='Please describe this image.'\",\n",
    "        ),\n",
    "        InputFieldMappingEntry(\n",
    "            name=\"image\",\n",
    "            source=\"/document/normalized_images/*/data\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[OutputFieldMappingEntry(name=\"response\", target_name=\"verbalizedImage\")],\n",
    ")\n",
    "\n",
    "\n",
    "# Create embedding skill for verbalized images\n",
    "verbalized_skill = AzureOpenAIEmbeddingSkill(\n",
    "        name=\"verblizedImage-embedding-skill\",\n",
    "        context=\"/document/normalized_images/*\",\n",
    "        inputs=[\n",
    "            InputFieldMappingEntry(\n",
    "                name=\"text\", source=\"/document/normalized_images/*/verbalizedImage\"\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            OutputFieldMappingEntry(\n",
    "                name=\"embedding\", target_name=\"verbalizedImage_vector\"\n",
    "            )\n",
    "        ],\n",
    "        resource_url=azure_openai_endpoint,\n",
    "        deployment_name=azure_openai_embedding_deployment,\n",
    "        dimensions=azure_openai_embeddings_dimensions,\n",
    "        model_name=azure_openai_embedding_deployment,\n",
    ")\n",
    "\n",
    "# Create shaper skill to shape the output\n",
    "shaper_skill = ShaperSkill(\n",
    "        name=\"#5\",\n",
    "        context=\"/document/normalized_images/*\",\n",
    "        inputs=[\n",
    "            InputFieldMappingEntry(\n",
    "                name=\"normalized_images\",\n",
    "                source=\"/document/normalized_images/*\",\n",
    "                inputs=[],\n",
    "            ),\n",
    "            InputFieldMappingEntry(\n",
    "                name=\"imagePath\",\n",
    "                source=f\"='{blob_artifacts}/'+$(/document/normalized_images/*/imagePath)\",\n",
    "                inputs=[],\n",
    "            ),\n",
    "        ],\n",
    "        outputs=[\n",
    "            OutputFieldMappingEntry(name=\"output\", target_name=\"new_normalized_images\")\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf7b53f",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "() Unexpected error validating provided resource. { \"error\": { \"code\": \"InvalidApiType\", \"message\": \"Unsupported Api Type.\" } }\nCode: \nMessage: Unexpected error validating provided resource. { \"error\": { \"code\": \"InvalidApiType\", \"message\": \"Unsupported Api Type.\" } }",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHttpResponseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 97\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msearch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocuments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     SearchIndexerSkillset,\n\u001b[32m      3\u001b[39m     SearchIndexerIndexProjection,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     IndexProjectionMode,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     15\u001b[39m skillSet = SearchIndexerSkillset(\n\u001b[32m     16\u001b[39m     name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-skillset\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     skills=[\n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m     ),\n\u001b[32m     95\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mindexer_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_or_update_skillset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskillSet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkillset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mskillSet.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m created successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\azure\\search\\documents\\indexes\\_search_indexer_client.py:668\u001b[39m, in \u001b[36mSearchIndexerClient.create_or_update_skillset\u001b[39m\u001b[34m(self, skillset, match_condition, skip_indexer_reset_requirement_for_cache, disable_cache_reprocessing_change_detection, **kwargs)\u001b[39m\n\u001b[32m    665\u001b[39m _validate_skillset(skillset)\n\u001b[32m    666\u001b[39m skillset_gen = skillset._to_generated() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(skillset, \u001b[33m\"\u001b[39m\u001b[33m_to_generated\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m skillset\n\u001b[32m--> \u001b[39m\u001b[32m668\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mskillsets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskillset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskillset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskillset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskillset_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreturn=representation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_indexer_reset_requirement_for_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_indexer_reset_requirement_for_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_cache_reprocessing_change_detection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable_cache_reprocessing_change_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(SearchIndexerSkillset, SearchIndexerSkillset._from_generated(result))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\azure\\search\\documents\\indexes\\_generated\\operations\\_skillsets_operations.py:451\u001b[39m, in \u001b[36mSkillsetsOperations.create_or_update\u001b[39m\u001b[34m(self, skillset_name, prefer, skillset, if_match, if_none_match, skip_indexer_reset_requirement_for_cache, disable_cache_reprocessing_change_detection, request_options, **kwargs)\u001b[39m\n\u001b[32m    449\u001b[39m     map_error(status_code=response.status_code, response=response, error_map=error_map)\n\u001b[32m    450\u001b[39m     error = \u001b[38;5;28mself\u001b[39m._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=response, model=error)\n\u001b[32m    453\u001b[39m deserialized = \u001b[38;5;28mself\u001b[39m._deserialize(\u001b[33m\"\u001b[39m\u001b[33mSearchIndexerSkillset\u001b[39m\u001b[33m\"\u001b[39m, pipeline_response.http_response)\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m:\n",
      "\u001b[31mHttpResponseError\u001b[39m: () Unexpected error validating provided resource. { \"error\": { \"code\": \"InvalidApiType\", \"message\": \"Unsupported Api Type.\" } }\nCode: \nMessage: Unexpected error validating provided resource. { \"error\": { \"code\": \"InvalidApiType\", \"message\": \"Unsupported Api Type.\" } }"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerSkillset,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    InputFieldMappingEntry,\n",
    "    AIServicesAccountIdentity,\n",
    "    SearchIndexerKnowledgeStore,\n",
    "    SearchIndexerKnowledgeStoreProjection,\n",
    "    SearchIndexerKnowledgeStoreFileProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    ")\n",
    "\n",
    "skillSet = SearchIndexerSkillset(\n",
    "    name=f\"{index_name}-skillset\",\n",
    "    skills=[\n",
    "        document_layout_skill,\n",
    "        gpt_skill,\n",
    "        azure_embedding_skill,\n",
    "        verbalized_skill,\n",
    "        shaper_skill,\n",
    "    ],\n",
    "    index_projection=SearchIndexerIndexProjection(\n",
    "        selectors=[\n",
    "            SearchIndexerIndexProjectionSelector(\n",
    "                target_index_name=index_name,\n",
    "                source_context=\"/document/text_sections/*\",\n",
    "                parent_key_field_name=\"text_document_id\",\n",
    "                mappings=[\n",
    "                    InputFieldMappingEntry(\n",
    "                        name=\"content_embedding\",\n",
    "                        source=\"/document/text_sections/*/text_vector\",\n",
    "                    ),\n",
    "                    InputFieldMappingEntry(\n",
    "                        name=\"content_text\",\n",
    "                        source=\"/document/text_sections/*/content\",\n",
    "                    ),\n",
    "                    InputFieldMappingEntry(\n",
    "                        name=\"locationMetadata\",\n",
    "                        source=\"/document/text_sections/*/locationMetadata\",\n",
    "                    ),\n",
    "                    InputFieldMappingEntry(\n",
    "                        name=\"document_title\", source=\"/document/document_title\"\n",
    "                    ),\n",
    "                ],\n",
    "            ),\n",
    "            SearchIndexerIndexProjectionSelector(\n",
    "                target_index_name=index_name,\n",
    "                source_context=\"/document/normalized_images/*\",\n",
    "                parent_key_field_name=\"image_document_id\",\n",
    "                mappings=[\n",
    "                    InputFieldMappingEntry(\n",
    "                        name=\"content_embedding\",\n",
    "                        source=\"/document/normalized_images/*/verbalizedImage_vector\",\n",
    "                    ),\n",
    "                    InputFieldMappingEntry(\n",
    "                        name=\"content_text\",\n",
    "                        source=\"/document/normalized_images/*/verbalizedImage\",\n",
    "                    ),\n",
    "                    InputFieldMappingEntry(\n",
    "                        name=\"content_path\",\n",
    "                        source=\"/document/normalized_images/*/new_normalized_images/imagePath\",\n",
    "                    ),\n",
    "                    InputFieldMappingEntry(\n",
    "                        name=\"locationMetadata\",\n",
    "                        source=\"/document/normalized_images/*/locationMetadata\",\n",
    "                    ),\n",
    "                    InputFieldMappingEntry(\n",
    "                        name=\"document_title\", source=\"/document/document_title\"\n",
    "                    ),\n",
    "                ],\n",
    "            ),\n",
    "        ],\n",
    "        parameters=SearchIndexerIndexProjectionsParameters(\n",
    "            projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS\n",
    "        ),\n",
    "    ),\n",
    "    cognitive_services_account=AIServicesAccountIdentity(\n",
    "        subdomain_url=azure_aiservices_endpoint,\n",
    "    ),\n",
    "    knowledge_store=SearchIndexerKnowledgeStore(\n",
    "        storage_connection_string=f\"ResourceId=/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.Storage/storageAccounts/{storage_account_name};\",\n",
    "        projections=[\n",
    "            SearchIndexerKnowledgeStoreProjection(\n",
    "                files=[\n",
    "                    SearchIndexerKnowledgeStoreFileProjectionSelector(\n",
    "                        storage_container=blob_artifacts,\n",
    "                        source=\"/document/normalized_images/*\",\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "await indexer_client.create_or_update_skillset(skillSet)\n",
    "print(f\"Skillset '{skillSet.name}' created successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
