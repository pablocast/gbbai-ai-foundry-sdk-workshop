{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ù§Ô∏è Azure AI Agents\n",
    "\n",
    "## Model Context Protocol (MCP) lab\n",
    "![flow](../../utils/model-context-protocol.gif)\n",
    "\n",
    "Playground to experiment the [Model Context Protocol](https://modelcontextprotocol.io/).\n",
    "\n",
    "This lab includes the following MCP servers:\n",
    "- Basic weather service: provide tools to get cities for a given country and retrieve random weather information for a specified city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='testconnection'></a>\n",
    "### üß™ Test the connection to the MCP servers and List Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3549, in run_code\n",
      "  |     exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"C:\\Users\\pablocastao\\AppData\\Local\\Temp\\ipykernel_27212\\59124045.py\", line 27, in <module>\n",
      "  |     asyncio.run(list_tools(f\"{server_url}\"))\n",
      "  |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "  |     return loop.run_until_complete(task)\n",
      "  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "  |     return f.result()\n",
      "  |            ^^^^^^^^^^\n",
      "  |   File \"C:\\Users\\pablocastao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\futures.py\", line 209, in result\n",
      "  |     raise self._exception.with_traceback(self._exception_tb)\n",
      "  |   File \"C:\\Users\\pablocastao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 272, in __step\n",
      "  |     result = coro.send(None)\n",
      "  |              ^^^^^^^^^^^^^^^\n",
      "  |   File \"C:\\Users\\pablocastao\\AppData\\Local\\Temp\\ipykernel_27212\\59124045.py\", line 15, in list_tools\n",
      "  |     async with sse_client(server_url, headers) as streams:\n",
      "  |   File \"C:\\Users\\pablocastao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 204, in __aenter__\n",
      "  |     return await anext(self.gen)\n",
      "  |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\mcp\\client\\sse.py\", line 43, in sse_client\n",
      "  |     async with anyio.create_task_group() as tg:\n",
      "  |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 772, in __aexit__\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"C:\\Users\\pablocastao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 222, in __aexit__\n",
      "    |     await self.gen.athrow(typ, value, traceback)\n",
      "    |   File \"C:\\Users\\pablocastao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 222, in __aexit__\n",
      "    |     await self.gen.athrow(typ, value, traceback)\n",
      "    |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1590, in stream\n",
      "    |     yield response\n",
      "    |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\httpx_sse\\_api.py\", line 70, in aconnect_sse\n",
      "    |     yield EventSource(response)\n",
      "    |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\mcp\\client\\sse.py\", line 53, in sse_client\n",
      "    |     event_source.response.raise_for_status()\n",
      "    |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\httpx\\_models.py\", line 829, in raise_for_status\n",
      "    |     raise HTTPStatusError(message, request=request, response=self)\n",
      "    | httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://aca-weather-5yrvw4ytnjmmm.jollysand-81bcf609.eastus.azurecontainerapps.io/sse'\n",
      "    | For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404\n",
      "    +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os, json, asyncio, time, requests\n",
    "from mcp import ClientSession\n",
    "from mcp.client.sse import sse_client\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime as pydatetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "server_url = \"https://\" + os.getenv(\"WEATHER_CONTAINERAPP_URL\") + \"/sse\"\n",
    "\n",
    "async def list_tools(server_url, authorization_header = None):\n",
    "    headers = {\"Authorization\": authorization_header} if authorization_header else None\n",
    "    async with sse_client(server_url, headers) as streams:\n",
    "        async with ClientSession(streams[0], streams[1]) as session:\n",
    "            await session.initialize()\n",
    "\n",
    "            response = await session.list_tools()\n",
    "            tools = response.tools\n",
    "    print(f\"‚úÖ Connected to server {server_url}\")\n",
    "    print(\"‚öôÔ∏è Tools:\")\n",
    "    for tool in tools:\n",
    "        print(f\"  - {tool.name}\")\n",
    "        print(f\"     Input Schema: {tool.inputSchema}\")\n",
    "    \n",
    "asyncio.run(list_tools(f\"{server_url}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Client and Load Azure AI Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure AI Projects\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    AgentEventHandler,\n",
    "    RunStep,\n",
    "    RunStepDeltaChunk,\n",
    "    ThreadMessage,\n",
    "    ThreadRun,\n",
    "    MessageDeltaChunk,\n",
    "    BingGroundingTool,\n",
    "    FilePurpose,\n",
    "    FileSearchTool,\n",
    "    FunctionTool,\n",
    "    ToolSet\n",
    ")\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=credential,\n",
    "    conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up MCP Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3547, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"C:\\Users\\pablocastao\\AppData\\Local\\Temp\\ipykernel_27212\\518087778.py\", line 9, in <module>\n",
      "  |     async with sse_client(server_url) as streams:\n",
      "  |   File \"C:\\Users\\pablocastao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 204, in __aenter__\n",
      "  |     return await anext(self.gen)\n",
      "  |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\mcp\\client\\sse.py\", line 43, in sse_client\n",
      "  |     async with anyio.create_task_group() as tg:\n",
      "  |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 772, in __aexit__\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"C:\\Users\\pablocastao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 222, in __aexit__\n",
      "    |     await self.gen.athrow(typ, value, traceback)\n",
      "    |   File \"C:\\Users\\pablocastao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 222, in __aexit__\n",
      "    |     await self.gen.athrow(typ, value, traceback)\n",
      "    |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1590, in stream\n",
      "    |     yield response\n",
      "    |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\httpx_sse\\_api.py\", line 70, in aconnect_sse\n",
      "    |     yield EventSource(response)\n",
      "    |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\mcp\\client\\sse.py\", line 53, in sse_client\n",
      "    |     event_source.response.raise_for_status()\n",
      "    |   File \"c:\\Users\\pablocastao\\OneDrive - Microsoft\\Work\\Clients\\Bancolombia\\gbbai-ai-foundry-sdk-workshop\\.venv\\Lib\\site-packages\\httpx\\_models.py\", line 829, in raise_for_status\n",
      "    |     raise HTTPStatusError(message, request=request, response=self)\n",
      "    | httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://aca-weather-5yrvw4ytnjmmm.jollysand-81bcf609.eastus.azurecontainerapps.io/sse'\n",
      "    | For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404\n",
      "    +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  Tool Call \n",
    "async def call_tool(mcp_session, function_name, function_args):\n",
    "    try:\n",
    "        func_response = await mcp_session.call_tool(function_name, function_args)\n",
    "        func_response_content = func_response.content\n",
    "    except Exception as e:\n",
    "        func_response_content = json.dumps({\"error\": str(e)})\n",
    "    return str(func_response_content)\n",
    "\n",
    "# Get Tool List\n",
    "async with sse_client(server_url) as streams:\n",
    "        async with ClientSession(streams[0], streams[1]) as session:\n",
    "            await session.initialize()\n",
    "            response = await session.list_tools()\n",
    "            tools = response.tools\n",
    "\n",
    "# Convert to openai tool format\n",
    "openai_tools = [{\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tool.name,\n",
    "                        \"parameters\": tool.inputSchema\n",
    "                    },\n",
    "                } for tool in tools\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'openai_tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     10\u001b[39m prompt_content = \u001b[33m\"\u001b[39m\u001b[33mWhat\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms the current weather in Medellin?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m project_client:\n\u001b[32m     13\u001b[39m     agent = project_client.agents.create_agent(\n\u001b[32m     14\u001b[39m         model=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mMODEL_DEPLOYMENT_NAME\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     15\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33mmy-assistant\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m         instructions=instructions,\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m         tools=\u001b[43mopenai_tools\u001b[49m\n\u001b[32m     18\u001b[39m     )\n\u001b[32m     19\u001b[39m     utils.print_ok(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreated agent, ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# Create thread for communication\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'openai_tools' is not defined"
     ]
    }
   ],
   "source": [
    "# Create agent with OpenApi tool and process assistant run\n",
    "model_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\")\n",
    "instructions = (\n",
    "    \"You are a helpful enterprise assistant at Contoso. \"\n",
    "    f\"Today's date is {pydatetime.now().strftime('%A, %b %d, %Y, %I:%M %p')}. \"\n",
    "    \"You have access to tools to get information about the weather, \"\n",
    ")\n",
    "\n",
    "prompt_content = \"What's the current weather in Medellin?\"\n",
    "\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=os.getenv(\"MODEL_DEPLOYMENT_NAME\"),\n",
    "        name=\"my-assistant\",\n",
    "        instructions=instructions,\n",
    "        tools=openai_tools\n",
    "    )\n",
    "    utils.print_ok(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create thread for communication\n",
    "    thread = project_client.agents.create_thread()\n",
    "    utils.print_ok(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "    # Create message to thread\n",
    "    message = project_client.agents.create_message(thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=prompt_content)\n",
    "    utils.print_ok(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process agent run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    utils.print_ok(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        utils.print_error(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "    # Print steps and function/tool details\n",
    "    run_steps = project_client.agents.list_run_steps(thread_id=thread.id, run_id=run.id)\n",
    "    for step in reversed(run_steps.data):\n",
    "        utils.print_ok(f\"Step {step['id']} status: {step['status']}\")\n",
    "        step_details = step.get(\"step_details\", {})\n",
    "        tool_calls = step_details.get(\"tool_calls\", [])\n",
    "        if tool_calls:\n",
    "            for call in tool_calls:\n",
    "                function_details = call.get(\"function\", {})\n",
    "                if function_details:\n",
    "                    utils.print_info(f\"Function details: {function_details}\")\n",
    "\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(f\"üó®Ô∏è {messages.data[0].content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
