{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f0b7d7",
   "metadata": {},
   "source": [
    "# üçè Observability & Tracing Demo with `azure-ai-projects` and `azure-ai-inference` üçé\n",
    "\n",
    "Bienvenido a este cuaderno tem√°tico de **Health & Fitness**, donde exploraremos c√≥mo configurar **observability** y **tracing** para:\n",
    "\n",
    "1. **Basic LLM calls** usando un `AIProjectClient`.\n",
    "2. **Multi-step** interacciones usando un **Agent** (como un Health Resource Agent).\n",
    "3. Enviar esos **traces** a **Azure Monitor** (Application Insights) para que puedas visualizarlos en **Azure AI Foundry**.\n",
    "\n",
    "> **Disclaimer**: Esta es una demostraci√≥n divertida de AI y observability! Cualquier referencia a rutinas de ejercicios, dietas o reg√≠menes de salud en el c√≥digo o en los prompts son √∫nicamente con fines **educational**. Siempre consulta a un profesional para obtener consejos de salud.\n",
    "\n",
    "## Contents\n",
    "1. **Initialization**: Configuraci√≥n del entorno, creaci√≥n de clientes.\n",
    "2. **Basic LLM Call**: Demostraci√≥n r√°pida de c√≥mo obtener completions de modelos.\n",
    "3. **Connections**: Listado de conexiones del proyecto.\n",
    "4. **Observability & Tracing**\n",
    "   - **Console / Local** tracing\n",
    "   - **Prompty / Aspire**: env√≠o de traces a un **OTLP endpoint** local\n",
    "   - **Azure Monitor** tracing: conexi√≥n a Application Insights\n",
    "   - **Verifying** de tus traces en Azure AI Foundry\n",
    "5. **Agent-based Example**:\n",
    "   - Creaci√≥n de un simple \"Health Resource Agent\" haciendo referencia a documentos de ejemplo.\n",
    "   - Conversaci√≥n de m√∫ltiples turnos con tracing.\n",
    "   - Cleanup.\n",
    "\n",
    "<img src=\"./seq-diagrams/1-observability.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13f9f3",
   "metadata": {},
   "source": [
    "## 1. Initialization & Setup\n",
    "**Prerequisites**:\n",
    "- Un archivo `.env` que contenga `PROJECT_CONNECTION_STRING` (y opcionalmente `MODEL_DEPLOYMENT_NAME`).\n",
    "- Roles/permissions en Azure AI Foundry que te permiten hacer inference & agent creation.\n",
    "- Un entorno local con paquetes `azure-ai-projects`, `azure-ai-inference`, `opentelemetry` instalados.\n",
    "\n",
    "**What we do**:\n",
    "- Cargar variables de entorno.\n",
    "- Inicializar `AIProjectClient`.\n",
    "- Verificar que podemos comunicarnos con un modelo (como `gpt-4o`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ccdace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully created AIProjectClient!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.inference.models import UserMessage, CompletionsFinishReason\n",
    "\n",
    "# Load environment variables\n",
    "notebook_path = Path().absolute()\n",
    "env_path = notebook_path.parent.parent / \".env\"  # Adjust path as needed\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "connection_string = os.environ.get(\"PROJECT_CONNECTION_STRING\")\n",
    "if not connection_string:\n",
    "    raise ValueError(\"üö® PROJECT_CONNECTION_STRING not set in .env.\")\n",
    "\n",
    "# Initialize AIProjectClient\n",
    "try:\n",
    "    project_client = AIProjectClient.from_connection_string(\n",
    "        credential=DefaultAzureCredential(), conn_str=connection_string\n",
    "    )\n",
    "    print(\"‚úÖ Successfully created AIProjectClient!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating AIProjectClient: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24461b",
   "metadata": {},
   "source": [
    "## 2. Basic LLM Call\n",
    "Realizaremos una solicitud r√°pida de chat completion para confirmar que todo est√© funcionando. Haremos una pregunta simple: \"¬øCu√°ntos pies hay en una milla?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7fcdaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí°Response:\n",
      "Una milla tiene 5,280 pies.\n",
      "\n",
      "Finish reason: CompletionsFinishReason.STOPPED\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Create a ChatCompletions client\n",
    "    inference_client = project_client.inference.get_chat_completions_client()\n",
    "    # Default to \"gpt-4o\" if no env var is set\n",
    "    model_name = os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "\n",
    "    user_question = \"¬øCu√°ntos pies hay en una milla?\"\n",
    "    response = inference_client.complete(\n",
    "        model=model_name, messages=[UserMessage(content=user_question)]\n",
    "    )\n",
    "    print(\"\\nüí°Response:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"\\nFinish reason:\", response.choices[0].finish_reason)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Could not complete the chat request:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b83517e",
   "metadata": {},
   "source": [
    "## 3. List & Inspect Connections\n",
    "Mira las **connections** que tiene tu proyecto: estas pueden ser Azure OpenAI u otros adjuntos de recursos. Solo las listaremos aqu√≠ para demostraci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b70793c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Found 6 total connections.\n",
      "1) Name: hub-demo-jrpn-connection-AISearch, Type: ConnectionType.AZURE_AI_SEARCH, Endpoint: https://agent-ai-search-jrpn.search.windows.net\n",
      "2) Name: hub-demo-jrpn-connection-AIServices_aoai, Type: ConnectionType.AZURE_OPEN_AI, Endpoint: https://agent-ai-servicesjrpn.openai.azure.com\n",
      "3) Name: hub-demo-jrpn-connection-AIServices, Type: ConnectionType.AZURE_AI_SERVICES, Endpoint: https://agent-ai-servicesjrpn.cognitiveservices.azure.com\n",
      "4) Name: hub-demo-jrpn-connection-BingSearch, Type: ConnectionType.API_KEY, Endpoint: https://api.bing.microsoft.com\n",
      "5) Name: project-demo-jrpn/workspaceblobstore, Type: ConnectionType.AZURE_BLOB_STORAGE, Endpoint: https://agentstoragejrpn.core.windows.net/727d94fe-693f-4d91-80b4-2972669685af-azureml-blobstore\n",
      "6) Name: project-demo-jrpn/workspaceartifactstore, Type: ConnectionType.AZURE_BLOB_STORAGE, Endpoint: https://agentstoragejrpn.core.windows.net/727d94fe-693f-4d91-80b4-2972669685af-azureml\n",
      "\n",
      "üåÄ Found 1 Azure OpenAI connections:\n",
      "   -> hub-demo-jrpn-connection-AIServices_aoai\n",
      "\n",
      "‚≠ê Default Azure AI Services connection:\n",
      "{\n",
      " \"name\": \"hub-demo-jrpn-connection-AIServices\",\n",
      " \"id\": \"/subscriptions/06d043e2-5a2e-46bf-bf48-fffee525f377/resourceGroups/lab-ai-foundry/providers/Microsoft.MachineLearningServices/workspaces/project-demo-jrpn/connections/hub-demo-jrpn-connection-AIServices\",\n",
      " \"authentication_type\": \"AAD\",\n",
      " \"connection_type\": \"ConnectionType.AZURE_AI_SERVICES\",\n",
      " \"endpoint_url\": \"https://agent-ai-servicesjrpn.cognitiveservices.azure.com\",\n",
      " \"key\": null\n",
      " \"token_credential\": null\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import ConnectionType\n",
    "\n",
    "all_conns = project_client.connections.list()\n",
    "print(f\"üîé Found {len(all_conns)} total connections.\")\n",
    "for idx, c in enumerate(all_conns):\n",
    "    print(\n",
    "        f\"{idx+1}) Name: {c.name}, Type: {c.connection_type}, Endpoint: {c.endpoint_url}\"\n",
    "    )\n",
    "\n",
    "# Filter for Azure OpenAI connections\n",
    "aoai_conns = project_client.connections.list(\n",
    "    connection_type=ConnectionType.AZURE_OPEN_AI\n",
    ")\n",
    "print(f\"\\nüåÄ Found {len(aoai_conns)} Azure OpenAI connections:\")\n",
    "for c in aoai_conns:\n",
    "    print(f\"   -> {c.name}\")\n",
    "\n",
    "# Get default connection of type AZURE_AI_SERVICES\n",
    "default_conn = project_client.connections.get_default(\n",
    "    connection_type=ConnectionType.AZURE_AI_SERVICES, include_credentials=False\n",
    ")\n",
    "if default_conn:\n",
    "    print(\"\\n‚≠ê Default Azure AI Services connection:\")\n",
    "    print(default_conn)\n",
    "else:\n",
    "    print(\"No default connection found for Azure AI Services.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce0c8f7",
   "metadata": {},
   "source": [
    "# 4. Observabilidad y Trazabilidad\n",
    "\n",
    "Queremos **collect telemetry** de nuestras llamadas a LLM, por ejemplo:\n",
    "- Marcas de tiempo de las solicitudes.\n",
    "- Latencia.\n",
    "- Errores potenciales.\n",
    "- Opcionalmente, las solicitudes y respuestas reales (si activas el registro de contenido).\n",
    "\n",
    "Con esta informaci√≥n, podremos diagnosticar problemas y optimizar el rendimiento de nuestros modelos.\n",
    "\n",
    "Mostraremos c√≥mo configurar:\n",
    "1. **Azure Monitor** instrumentation with Application Insights.\n",
    "2. **Viewing** your traces in Azure AI Foundry's portal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767143a",
   "metadata": {},
   "source": [
    "### 4.1 Habilitar OpenTelemetry para Azure AI Inference\n",
    "  \n",
    "Establecemos variables de entorno para asegurar:\n",
    "1. **Prompt content** se captura (optional!)\n",
    "2. El **Azure SDK** utiliza OpenTelemetry como implementaci√≥n de trazabilidad.\n",
    "3. Llamamos a `AIInferenceInstrumentor().instrument()` para parchear y habilitar la instrumentaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ef06776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Azure AI Inference instrumentation enabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.inference.tracing import AIInferenceInstrumentor\n",
    "\n",
    "# (Optional) capture prompt & completion contents in traces\n",
    "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"  # or 'false'\n",
    "\n",
    "# Let the Azure SDK know we want to use OpenTelemetry\n",
    "os.environ[\"AZURE_SDK_TRACING_IMPLEMENTATION\"] = \"opentelemetry\"\n",
    "\n",
    "# Instrument the Azure AI Inference client library\n",
    "AIInferenceInstrumentor().instrument()\n",
    "print(\"‚úÖ Azure AI Inference instrumentation enabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c0fdd4",
   "metadata": {},
   "source": [
    "Ahora configuraremos el tracing a **Application Insights**, que reenviar√° tus logs a la p√°gina de **Azure AI Foundry** **Tracing**.\n",
    "\n",
    "**Steps**:\n",
    "1. En AI Foundry, ve a la pesta√±a **Tracing** de tu proyecto, y asocia (o crea) un recurso de **Application Insights**.\n",
    "2. En el c√≥digo, llama a `project_client.telemetry.get_connection_string()` para obtener la clave de instrumentaci√≥n.\n",
    "3. Usa `azure.monitor.opentelemetry.configure_azure_monitor(...)` con esa conexi√≥n.\n",
    "4. Realiza una llamada de inferencia -> los logs aparecer√°n en el portal de Foundry (y en Azure Monitor).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "552014a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Found App Insights connection string, configuring...\n",
      "\n",
      "ü§ñ Response (logged to App Insights):\n",
      "Absolutely! There are plenty of at-home cardio exercises you can do with little to no equipment. Here are some easy and effective ones:\n",
      "\n",
      "1. **Jumping Jacks**: A great full-body workout that increases your heart rate quickly.\n",
      "2. **High Knees**: Jog in place while lifting your knees as high as possible with each step.\n",
      "3. **Butt Kicks**: Jog in place while kicking your heels up toward your butt with each step.\n",
      "4. **Burpees**: Start from a standing position, move into a squat, kick your feet back into a plank, jump your feet back to the squat, then jump up and repeat.\n",
      "5. **Mountain Climbers**: Start in a plank position, then alternately bring your knees toward your chest in a running motion.\n",
      "6. **Jump Rope**: If you have a jump rope at home, this is a fantastic cardio exercise.\n",
      "7. **Dancing**: Put on some music and dance around your living room. It's fun and effective!\n",
      "8. **Stair Climbing**: If you have stairs at home, running or walking up and down them can be a great workout.\n",
      "9. **Running in Place**: Simply jog in place with vigor, lifting your knees and swinging your arms.\n",
      "10. **Shadow Boxing**: Assume a boxing stance and throw punches in the air, mixing in some footwork.\n",
      "\n",
      "Remember to warm up before starting your workout and cool down afterward with some stretches. It's also key to stay hydrated and listen to your body, especially if you're new to these activities.\n"
     ]
    }
   ],
   "source": [
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from azure.ai.inference.models import UserMessage\n",
    "\n",
    "app_insights_conn_str = project_client.telemetry.get_connection_string()\n",
    "if app_insights_conn_str:\n",
    "    print(\"üîß Found App Insights connection string, configuring...\")\n",
    "    configure_azure_monitor(connection_string=app_insights_conn_str)\n",
    "    # Optionally add more instrumentation (for openai or langchain):\n",
    "    project_client.telemetry.enable()\n",
    "\n",
    "    # Let's do a test call that logs to AI Foundry's Tracing page\n",
    "    try:\n",
    "        with project_client.inference.get_chat_completions_client() as client:\n",
    "            prompt_msg = \"Any easy at-home cardio exercise recommendations?\"\n",
    "            response = client.complete(\n",
    "                model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
    "                messages=[UserMessage(content=prompt_msg)],\n",
    "            )\n",
    "            print(\"\\nü§ñ Response (logged to App Insights):\")\n",
    "            print(response.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Chat completions with Azure Monitor example failed:\", e)\n",
    "else:\n",
    "    print(\"No Application Insights connection string is configured in this project.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4991833",
   "metadata": {},
   "source": [
    "### 4.3 Visualizaci√≥n de Trazas en Azure AI Foundry\n",
    "Despu√©s de ejecutar el c√≥digo anterior:\n",
    "1. Ve a tu proyecto de AI Foundry.\n",
    "2. Haz clic en **Tracing** en la barra lateral.\n",
    "3. Deber√≠as ver los registros (logs) de tus llamadas.\n",
    "4. Filtra, expande o explora los detalles seg√∫n lo necesites.\n",
    "\n",
    "Adem√°s, si deseas paneles de control m√°s avanzados, puedes abrir tu recurso de **Application Insights** desde Foundry. En el portal de App Insights obtendr√°s otras funciones como detalles de transacciones de extremo a extremo, registros de consultas, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dbb932",
   "metadata": {},
   "source": [
    "# 5. Agent-based Example\n",
    "\n",
    "Ahora vamos a crear un **Health Resource Agent** que hace referencia a documentos de ejemplo sobre recetas o pautas, y luego demostramos:\n",
    "1. La creaci√≥n de un Agente con instrucciones.\n",
    "2. La creaci√≥n de un hilo de conversaci√≥n.\n",
    "3. La ejecuci√≥n de consultas en m√∫ltiples pasos con **observability** habilitada.\n",
    "4. Opcionalmente, la limpieza de recursos al final.\n",
    "\n",
    "> El enfoque basado en agentes es √∫til cuando deseas flujos de conversaci√≥n m√°s sofisticados o **tool usage** (como la b√∫squeda en archivos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ad934",
   "metadata": {},
   "source": [
    "## 5.1 Create Sample Files & Vector Store\n",
    "We'll create dummy `.md` files about recipes/guidelines, then push them into a **vector store** so our agent can do semantic search.\n",
    "\n",
    "(*This portion is a quick summary‚Äîsee [the other file-search tutorial] if you need more details.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e09113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Created sample resource files: recipes.md, guidelines.md\n",
      "‚úÖ Uploaded: recipes.md -> File ID: assistant-QUcHsy34TcSEThMkTZZd6y\n",
      "‚úÖ Uploaded: guidelines.md -> File ID: assistant-4iffm3auM2xn1TMonLAg3q\n",
      "üéâ Created vector store 'health_resources_example', ID: vs_Gas3OgN0cE8xUsM8CfhD184h\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import (\n",
    "    FileSearchTool,\n",
    "    FilePurpose,\n",
    "    MessageTextContent,\n",
    "    MessageRole,\n",
    ")\n",
    "\n",
    "\n",
    "def create_sample_files():\n",
    "    \"\"\"Create some local .md files with sample text.\"\"\"\n",
    "    recipes_md = \"\"\"# Base de Datos de Recetas Saludables\\n\\n\"\n",
    "        \"## Recetas sin Gluten\\n\"\n",
    "        \"1. Taz√≥n de Quinoa\\n\"\n",
    "        \"   - Ingredientes: quinoa, verduras, aceite de oliva\\n\"\n",
    "        \"   - Instrucciones: Cocer la quinoa, agregar verduras\\n\\n\"\n",
    "        \"2. Pasta de Arroz\\n\"\n",
    "        \"   - Ingredientes: pasta de arroz, verduras mixtas\\n\"\n",
    "        \"   - Instrucciones: Hervir la pasta, saltear las verduras\\n\\n\"\n",
    "        \"## Recetas para Diab√©ticos\\n\"\n",
    "        \"1. Salteado Bajo en Carbohidratos\\n\"\n",
    "        \"   - Ingredientes: pollo, verduras, salsa de tamari\\n\"\n",
    "        \"   - Instrucciones: Cocinar el pollo, agregar verduras\\n\\n\"\n",
    "        \"## Recetas Saludables para el Coraz√≥n\\n\"\n",
    "        \"1. Salm√≥n al Horno\\n\"\n",
    "        \"   - Ingredientes: salm√≥n, lim√≥n, hierbas\\n\"\n",
    "        \"   - Instrucciones: Sazonar el salm√≥n, hornear\\n\\n\"\n",
    "        \"2. Taz√≥n Mediterr√°neo\\n\"\n",
    "        \"   - Ingredientes: garbanzos, verduras, tahini\\n\"\n",
    "        \"   - Instrucciones: Combinar ingredientes\\n\"\"\"\n",
    "\n",
    "    guidelines_md = \"\"\"# Pautas Alimentarias\n",
    "\n",
    "        ## Pautas Generales\n",
    "        - Consume una variedad de alimentos\n",
    "        - Controla el tama√±o de las porciones\n",
    "        - Mantente hidratado\n",
    "\n",
    "        ## Dietas Especiales\n",
    "        1. Dieta sin Gluten\n",
    "        - Evita el trigo, la cebada y el centeno\n",
    "        - Enf√≥cate en alimentos naturalmente sin gluten\n",
    "\n",
    "        2. Dieta para Diab√©ticos\n",
    "        - Monitorea la ingesta de carbohidratos\n",
    "        - Elige alimentos de bajo √≠ndice gluc√©mico\n",
    "\n",
    "        3. Dieta Saludable para el Coraz√≥n\n",
    "        - Limita las grasas saturadas\n",
    "        - Elige prote√≠nas magras\"\"\"\n",
    "\n",
    "    with open(\"recipes.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(recipes_md)\n",
    "    with open(\"guidelines.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(guidelines_md)\n",
    "\n",
    "    print(\"üìÑ Created sample resource files: recipes.md, guidelines.md\")\n",
    "    return [\"recipes.md\", \"guidelines.md\"]\n",
    "\n",
    "\n",
    "sample_files = create_sample_files()\n",
    "\n",
    "\n",
    "def create_vector_store(files, store_name=\"my_health_resources\"):\n",
    "    try:\n",
    "        uploaded_ids = []\n",
    "        for fp in files:\n",
    "            upl = project_client.agents.upload_file_and_poll(\n",
    "                file_path=fp, purpose=FilePurpose.AGENTS  # Add FilePurpose.AGENTS here\n",
    "            )\n",
    "            uploaded_ids.append(upl.id)\n",
    "            print(f\"‚úÖ Uploaded: {fp} -> File ID: {upl.id}\")\n",
    "\n",
    "        # Create vector store from these file IDs\n",
    "        vs = project_client.agents.create_vector_store_and_poll(\n",
    "            file_ids=uploaded_ids, name=store_name\n",
    "        )\n",
    "        print(f\"üéâ Created vector store '{store_name}', ID: {vs.id}\")\n",
    "        return vs, uploaded_ids\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating vector store: {e}\")\n",
    "        return None, []\n",
    "\n",
    "\n",
    "vector_store, file_ids = None, []\n",
    "if sample_files:\n",
    "    vector_store, file_ids = create_vector_store(\n",
    "        sample_files, store_name=\"health_resources_example\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145eb186",
   "metadata": {},
   "source": [
    "## 5.2 Create a Health Resource Agent\n",
    "\n",
    "Crearemos un **FileSearchTool** que haga referencia al vector store, luego crearemos un agente con instrucciones de que debe:\n",
    "\n",
    "1. Proporcionar descargos de responsabilidad.\n",
    "2. Ofrecer consejos generales sobre nutrici√≥n o recetas.\n",
    "3. Citar fuentes cuando sea posible.\n",
    "4. Fomentar la consulta con profesionales para obtener asesoramiento m√©dico m√°s completo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f604175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Created agent 'health-search-agent' with ID: asst_DWGnIKu7mI7PjHaRrrB5YAjf\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import FileSearchTool, FilePurpose\n",
    "from azure.ai.projects.models import ConnectionType, MessageTextContent, MessageRole\n",
    "\n",
    "\n",
    "def create_health_agent(vs_id):\n",
    "    try:\n",
    "        # The tool references our vector store so the agent can search it\n",
    "        file_search_tool = FileSearchTool(vector_store_ids=[vs_id])\n",
    "\n",
    "        instructions = \"\"\"\n",
    "            Eres un asesor de recursos de salud con acceso a archivos de recetas y gu√≠as diet√©ticas.\n",
    "            T√∫:\n",
    "            1. Siempre presenta exenciones de responsabilidad (no eres un profesional m√©dico)\n",
    "            2. Proporciona referencias a archivos cuando sea posible.\n",
    "            3. Enf√≥cate en consejos generales de nutrici√≥n o recetas.\n",
    "            4. Fomenta la consulta con profesionales para obtener un asesoramiento m√°s detallado.\n",
    "        \"\"\"\n",
    "\n",
    "        agent = project_client.agents.create_agent(\n",
    "            model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
    "            name=\"health-search-agent\",\n",
    "            instructions=instructions,\n",
    "            tools=file_search_tool.definitions,\n",
    "            tool_resources=file_search_tool.resources,\n",
    "        )\n",
    "        print(f\"üéâ Created agent '{agent.name}' with ID: {agent.id}\")\n",
    "        return agent\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating health agent: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "health_agent = None\n",
    "if vector_store:\n",
    "    health_agent = create_health_agent(vector_store.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6995a6",
   "metadata": {},
   "source": [
    "## 5.3 Using the Agent\n",
    "Vamos a crear un n**thread** y preguntarle al agente algunas preguntas. Nos apoyaremos en la configuraci√≥n de **observability** que ya establecimos para que cada paso se rastree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e5b4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Created new thread, ID: thread_8mFjhxT9TTiPxCZrjlzweXfC\n",
      "User asked: '¬øPodr√≠as sugerir una receta de almuerzo sin gluten?'\n",
      "Run finished with status: RunStatus.COMPLETED\n",
      "User asked: 'Mu√©strame algunas ideas de comidas saludables para el coraz√≥n.'\n",
      "Run finished with status: RunStatus.COMPLETED\n",
      "User asked: '¬øQu√© pautas tienes para alguien con diabetes?'\n",
      "Run finished with status: RunStatus.COMPLETED\n"
     ]
    }
   ],
   "source": [
    "def create_thread():\n",
    "    try:\n",
    "        thread = project_client.agents.create_thread()\n",
    "        print(f\"üìù Created new thread, ID: {thread.id}\")\n",
    "        return thread\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not create thread: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def ask_question(thread_id, agent_id, user_question):\n",
    "    try:\n",
    "        # 1) Add user message\n",
    "        msg = project_client.agents.create_message(\n",
    "            thread_id=thread_id, role=\"user\", content=user_question\n",
    "        )\n",
    "        print(f\"User asked: '{user_question}'\")\n",
    "        # 2) Create & process a run\n",
    "        run = project_client.agents.create_and_process_run(\n",
    "            thread_id=thread_id, agent_id=agent_id\n",
    "        )\n",
    "        print(f\"Run finished with status: {run.status}\")\n",
    "        if run.last_error:\n",
    "            print(\"Error details:\", run.last_error)\n",
    "        return run\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error asking question: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if health_agent:\n",
    "    thread = create_thread()\n",
    "    if thread:\n",
    "        # Let's ask a few sample questions\n",
    "        queries = [\n",
    "            \"¬øPodr√≠as sugerir una receta de almuerzo sin gluten?\",\n",
    "            \"Mu√©strame algunas ideas de comidas saludables para el coraz√≥n.\",\n",
    "            \"¬øQu√© pautas tienes para alguien con diabetes?\",\n",
    "        ]\n",
    "        for q in queries:\n",
    "            ask_question(thread.id, health_agent.id, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c61d8d",
   "metadata": {},
   "source": [
    "### 5.3.1 Viewing the conversation\n",
    "We can retrieve the conversation messages to see how the agent responded, check if it cited file passages, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c57935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üó£Ô∏è Conversation:\n",
      "[USER]: ¬øPodr√≠as sugerir una receta de almuerzo sin gluten?\n",
      "\n",
      "[ASSISTANT]: Claro, aqu√≠ tienes una receta de almuerzo sin gluten que puedes encontrar en los archivos:\n",
      "\n",
      "### Taz√≥n de Quinoa\n",
      "\n",
      "#### Ingredientes:\n",
      "- Quinoa\n",
      "- Verduras de tu elecci√≥n (como pimientos, zanahorias, espinacas)\n",
      "- Aceite de oliva\n",
      "\n",
      "#### Instrucciones:\n",
      "1. **Cocinar la quinoa**: Enjuaga una taza de quinoa bajo agua fr√≠a. En una cacerola, lleva a ebullici√≥n 2 tazas de agua. Agrega la quinoa enjuagada, reduce el fuego y cubre. Cocina a fuego lento durante 15 minutos o hasta que el agua se haya absorbido y la quinoa est√© tierna.\n",
      "2. **Preparar las verduras**: Mientras se cocina la quinoa, corta las verduras en trozos peque√±os. Puedes saltearlas en una sart√©n con un poco de aceite de oliva hasta que est√©n tiernas, o tambi√©n puedes agregarlas crudas si prefieres.\n",
      "3. **Combinar**: Mezcla la quinoa cocida con las verduras. A√±ade un chorrito de aceite de oliva y sazona con sal y pimienta al gusto.\n",
      "\n",
      "Puedes adaptar esta receta agregando tus prote√≠nas favoritas como pollo o tofu si lo deseas.\n",
      "\n",
      "Recuerda siempre consultar con un profesional de salud para personalizar tu dieta seg√∫n tus necesidades espec√≠ficas„Äê4:0‚Ä†source„Äë.\n",
      "\n",
      "[USER]: Mu√©strame algunas ideas de comidas saludables para el coraz√≥n.\n",
      "\n",
      "[ASSISTANT]: Aqu√≠ tienes algunas ideas de comidas saludables para el coraz√≥n:\n",
      "\n",
      "1. **Salm√≥n al Horno**\n",
      "   - **Ingredientes**: \n",
      "     - Salm√≥n\n",
      "     - Lim√≥n\n",
      "     - Hierbas\n",
      "   - **Instrucciones**: \n",
      "     - Sazona el salm√≥n con jugo de lim√≥n y hierbas al gusto.\n",
      "     - Hornea a 180¬∞C durante 20 minutos o hasta que el salm√≥n est√© completamente cocido.\n",
      "     \n",
      "2. **Taz√≥n Mediterr√°neo**\n",
      "   - **Ingredientes**: \n",
      "     - Garbanzos\n",
      "     - Verduras (como pepino, tomate, pimiento)\n",
      "     - Tahini\n",
      "   - **Instrucciones**: \n",
      "     - Combina los garbanzos cocidos con las verduras picadas.\n",
      "     - Agrega una cucharada de tahini para darle sabor y mezcla bien.\n",
      "     \n",
      "Estas recetas est√°n dise√±adas para ser bajas en grasas saturadas y hacer uso de prote√≠nas magras, lo que puede contribuir a la salud del coraz√≥n„Äê8:0‚Ä†source„Äë„Äê8:1‚Ä†source„Äë.\n",
      "\n",
      "Recuerda que siempre es una buena idea consultar con un profesional de salud para obtener un asesoramiento m√°s detallado y personalizado.\n",
      "\n",
      "[USER]: ¬øQu√© pautas tienes para alguien con diabetes?\n",
      "\n",
      "[ASSISTANT]: Aqu√≠ tienes algunas pautas generales para alguien con diabetes, seg√∫n los archivos:\n",
      "\n",
      "### Pautas Generales para Diab√©ticos\n",
      "1. **Monitorea la ingesta de carbohidratos**:\n",
      "   - Es importante tener en cuenta la cantidad de carbohidratos que consumes, ya que estos tienen un impacto directo en los niveles de az√∫car en la sangre. \n",
      "   \n",
      "2. **Elige alimentos de bajo √≠ndice gluc√©mico**:\n",
      "   - Opta por alimentos que tengan un √≠ndice gluc√©mico bajo, ya que estos causan una menor subida de az√∫car en la sangre. Ejemplos de estos alimentos incluyen vegetales, frutas frescas, legumbres y granos enteros.\n",
      "\n",
      "**Otras recomendaciones importantes**:\n",
      "- Consumir una variedad de alimentos para asegurar una ingesta equilibrada de nutrientes.\n",
      "- Controlar el tama√±o de las porciones para evitar el exceso de calor√≠as y carbohidratos.\n",
      "- Mantenerse hidratado bebiendo suficiente agua a lo largo del d√≠a„Äê12:0‚Ä†source„Äë.\n",
      "\n",
      "Siempre es recomendable consultar con un profesional de la salud para obtener asesoramiento personalizado y ajustar las pautas a tus necesidades individuales.\n",
      "\n",
      "\n",
      "üìé Checking for citations...\n",
      "- Citation snippet: '„Äê12:0‚Ä†source„Äë' from file ID: assistant-4iffm3auM2xn1TMonLAg3q\n",
      "- Citation snippet: '„Äê8:0‚Ä†source„Äë' from file ID: assistant-QUcHsy34TcSEThMkTZZd6y\n",
      "- Citation snippet: '„Äê8:1‚Ä†source„Äë' from file ID: assistant-4iffm3auM2xn1TMonLAg3q\n",
      "- Citation snippet: '„Äê4:0‚Ä†source„Äë' from file ID: assistant-QUcHsy34TcSEThMkTZZd6y\n"
     ]
    }
   ],
   "source": [
    "def display_thread(thread_id):\n",
    "    try:\n",
    "        messages = project_client.agents.list_messages(thread_id=thread_id)\n",
    "        print(\"\\nüó£Ô∏è Conversation:\")\n",
    "        for m in reversed(messages.data):\n",
    "            if m.content:\n",
    "                last_content = m.content[-1]\n",
    "                if hasattr(last_content, \"text\"):\n",
    "                    print(f\"[{m.role.upper()}]: {last_content.text.value}\\n\")\n",
    "\n",
    "        print(\"\\nüìé Checking for citations...\")\n",
    "        for c in messages.file_citation_annotations:\n",
    "            print(\n",
    "                f\"- Citation snippet: '{c.text}' from file ID: {c.file_citation['file_id']}\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not display thread: {e}\")\n",
    "\n",
    "\n",
    "# If we created a thread above, let's read it\n",
    "if health_agent and thread:\n",
    "    display_thread(thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7420c39",
   "metadata": {},
   "source": [
    "# 6. Cleanup\n",
    "If desired, we can remove the vector store, files, and agent to keep things tidy. (In a real solution, you might keep them around.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f473cddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Deleted vector store.\n",
      "üóëÔ∏è Deleted uploaded files.\n",
      "üóëÔ∏è Deleted health agent.\n",
      "üóëÔ∏è Deleted local sample files.\n"
     ]
    }
   ],
   "source": [
    "def cleanup_resources():\n",
    "    try:\n",
    "        if \"vector_store\" in globals() and vector_store:\n",
    "            project_client.agents.delete_vector_store(vector_store.id)\n",
    "            print(\"üóëÔ∏è Deleted vector store.\")\n",
    "\n",
    "        if \"file_ids\" in globals() and file_ids:\n",
    "            for fid in file_ids:\n",
    "                project_client.agents.delete_file(fid)\n",
    "            print(\"üóëÔ∏è Deleted uploaded files.\")\n",
    "\n",
    "        if \"health_agent\" in globals() and health_agent:\n",
    "            project_client.agents.delete_agent(health_agent.id)\n",
    "            print(\"üóëÔ∏è Deleted health agent.\")\n",
    "\n",
    "        if \"sample_files\" in globals() and sample_files:\n",
    "            for sf in sample_files:\n",
    "                if os.path.exists(sf):\n",
    "                    os.remove(sf)\n",
    "            print(\"üóëÔ∏è Deleted local sample files.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error cleaning up: {e}\")\n",
    "\n",
    "\n",
    "cleanup_resources()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  },
  "name": "Observability_and_Tracing_Comprehensive"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
