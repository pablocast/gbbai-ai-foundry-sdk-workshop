{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f0b7d7",
   "metadata": {},
   "source": [
    "# üçè Observability & Tracing Demo with `azure-ai-projects` and `azure-ai-inference` üçé\n",
    "\n",
    "Bienvenido a este cuaderno tem√°tico de **Health & Fitness**, donde exploraremos c√≥mo configurar **observability** y **tracing** para:\n",
    "\n",
    "1. **Basic LLM calls** usando un `AIProjectClient`.\n",
    "2. **Multi-step** interacciones usando un **Agent** (como un Health Resource Agent).\n",
    "3. Enviar esos **traces** a **Azure Monitor** (Application Insights) para que puedas visualizarlos en **Azure AI Foundry**.\n",
    "\n",
    "> **Disclaimer**: Esta es una demostraci√≥n divertida de AI y observability! Cualquier referencia a rutinas de ejercicios, dietas o reg√≠menes de salud en el c√≥digo o en los prompts son √∫nicamente con fines **educational**. Siempre consulta a un profesional para obtener consejos de salud.\n",
    "\n",
    "## Contents\n",
    "1. **Initialization**: Configuraci√≥n del entorno, creaci√≥n de clientes.\n",
    "2. **Basic LLM Call**: Demostraci√≥n r√°pida de c√≥mo obtener completions de modelos.\n",
    "3. **Connections**: Listado de conexiones del proyecto.\n",
    "4. **Observability & Tracing**\n",
    "   - **Console / Local** tracing\n",
    "   - **Prompty / Aspire**: env√≠o de traces a un **OTLP endpoint** local\n",
    "   - **Azure Monitor** tracing: conexi√≥n a Application Insights\n",
    "   - **Verifying** de tus traces en Azure AI Foundry\n",
    "5. **Agent-based Example**:\n",
    "   - Creaci√≥n de un simple \"Health Resource Agent\" haciendo referencia a documentos de ejemplo.\n",
    "   - Conversaci√≥n de m√∫ltiples turnos con tracing.\n",
    "   - Cleanup.\n",
    "\n",
    "<img src=\"./seq-diagrams/1-observability.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13f9f3",
   "metadata": {},
   "source": [
    "## 1. Initialization & Setup\n",
    "**Prerequisites**:\n",
    "- Un archivo `.env` que contenga `PROJECT_CONNECTION_STRING` (y opcionalmente `MODEL_DEPLOYMENT_NAME`).\n",
    "- Roles/permissions en Azure AI Foundry que te permiten hacer inference & agent creation.\n",
    "- Un entorno local con paquetes `azure-ai-projects`, `azure-ai-inference`, `opentelemetry` instalados.\n",
    "\n",
    "**What we do**:\n",
    "- Cargar variables de entorno.\n",
    "- Inicializar `AIProjectClient`.\n",
    "- Verificar que podemos comunicarnos con un modelo (como `gpt-4o`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ccdace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully created AIProjectClient!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.inference.models import UserMessage, CompletionsFinishReason\n",
    "\n",
    "# Load environment variables\n",
    "notebook_path = Path().absolute()\n",
    "env_path = notebook_path.parent.parent / \".env\"  # Adjust path as needed\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "connection_string = os.environ.get(\"PROJECT_CONNECTION_STRING\")\n",
    "if not connection_string:\n",
    "    raise ValueError(\"üö® PROJECT_CONNECTION_STRING not set in .env.\")\n",
    "\n",
    "# Initialize AIProjectClient\n",
    "try:\n",
    "    project_client = AIProjectClient.from_connection_string(\n",
    "        credential=DefaultAzureCredential(), conn_str=connection_string\n",
    "    )\n",
    "    print(\"‚úÖ Successfully created AIProjectClient!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating AIProjectClient: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24461b",
   "metadata": {},
   "source": [
    "## 2. Basic LLM Call\n",
    "Realizaremos una solicitud r√°pida de chat completion para confirmar que todo est√© funcionando. Haremos una pregunta simple: \"¬øCu√°ntos pies hay en una milla?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fcdaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí°Response:\n",
      "Hay 5280 pies en una milla.\n",
      "\n",
      "Finish reason: CompletionsFinishReason.STOPPED\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Create a ChatCompletions client\n",
    "    inference_client = project_client.inference.get_chat_completions_client()\n",
    "    # Default to \"gpt-4o\" if no env var is set\n",
    "    model_name = os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "\n",
    "    user_question = \"¬øCu√°ntos pies hay en una milla?\"\n",
    "    response = inference_client.complete(\n",
    "        model=model_name, messages=[UserMessage(content=user_question)]\n",
    "    )\n",
    "    print(\"\\nüí°Response:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"\\nFinish reason:\", response.choices[0].finish_reason)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Could not complete the chat request:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b83517e",
   "metadata": {},
   "source": [
    "## 3. List & Inspect Connections\n",
    "Mira las **connections** que tiene tu proyecto: estas pueden ser Azure OpenAI u otros adjuntos de recursos. Solo las listaremos aqu√≠ para demostraci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70793c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Found 6 total connections.\n",
      "1) Name: hub-demo-ivii-connection-AISearch, Type: ConnectionType.AZURE_AI_SEARCH, Endpoint: https://agent-ai-search-ivii.search.windows.net\n",
      "2) Name: hub-demo-ivii-connection-AIServices_aoai, Type: ConnectionType.AZURE_OPEN_AI, Endpoint: https://agent-ai-servicesivii.openai.azure.com\n",
      "3) Name: hub-demo-ivii-connection-AIServices, Type: ConnectionType.AZURE_AI_SERVICES, Endpoint: https://agent-ai-servicesivii.cognitiveservices.azure.com\n",
      "4) Name: hub-demo-ivii-connection-BingSearch, Type: ConnectionType.API_KEY, Endpoint: https://api.bing.microsoft.com\n",
      "5) Name: project-demo-ivii/workspaceblobstore, Type: ConnectionType.AZURE_BLOB_STORAGE, Endpoint: https://agentstorageivii.core.windows.net/21203267-ab62-41f0-bc84-12a9170fba7b-azureml-blobstore\n",
      "6) Name: project-demo-ivii/workspaceartifactstore, Type: ConnectionType.AZURE_BLOB_STORAGE, Endpoint: https://agentstorageivii.core.windows.net/21203267-ab62-41f0-bc84-12a9170fba7b-azureml\n",
      "\n",
      "üåÄ Found 1 Azure OpenAI connections:\n",
      "   -> hub-demo-ivii-connection-AIServices_aoai\n",
      "\n",
      "‚≠ê Default Azure AI Services connection:\n",
      "{\n",
      " \"name\": \"hub-demo-ivii-connection-AIServices\",\n",
      " \"id\": \"/subscriptions/06d043e2-5a2e-46bf-bf48-fffee525f377/resourceGroups/lab-ai-foundry/providers/Microsoft.MachineLearningServices/workspaces/project-demo-ivii/connections/hub-demo-ivii-connection-AIServices\",\n",
      " \"authentication_type\": \"AAD\",\n",
      " \"connection_type\": \"ConnectionType.AZURE_AI_SERVICES\",\n",
      " \"endpoint_url\": \"https://agent-ai-servicesivii.cognitiveservices.azure.com\",\n",
      " \"key\": null\n",
      " \"token_credential\": null\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import ConnectionType\n",
    "\n",
    "all_conns = project_client.connections.list()\n",
    "print(f\"üîé Found {len(all_conns)} total connections.\")\n",
    "for idx, c in enumerate(all_conns):\n",
    "    print(\n",
    "        f\"{idx+1}) Name: {c.name}, Type: {c.connection_type}, Endpoint: {c.endpoint_url}\"\n",
    "    )\n",
    "\n",
    "# Filter for Azure OpenAI connections\n",
    "aoai_conns = project_client.connections.list(\n",
    "    connection_type=ConnectionType.AZURE_OPEN_AI\n",
    ")\n",
    "print(f\"\\nüåÄ Found {len(aoai_conns)} Azure OpenAI connections:\")\n",
    "for c in aoai_conns:\n",
    "    print(f\"   -> {c.name}\")\n",
    "\n",
    "# Get default connection of type AZURE_AI_SERVICES\n",
    "default_conn = project_client.connections.get_default(\n",
    "    connection_type=ConnectionType.AZURE_AI_SERVICES, include_credentials=False\n",
    ")\n",
    "if default_conn:\n",
    "    print(\"\\n‚≠ê Default Azure AI Services connection:\")\n",
    "    print(default_conn)\n",
    "else:\n",
    "    print(\"No default connection found for Azure AI Services.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce0c8f7",
   "metadata": {},
   "source": [
    "# 4. Observabilidad y Trazabilidad\n",
    "\n",
    "Queremos **collect telemetry** de nuestras llamadas a LLM, por ejemplo:\n",
    "- Marcas de tiempo de las solicitudes.\n",
    "- Latencia.\n",
    "- Errores potenciales.\n",
    "- Opcionalmente, las solicitudes y respuestas reales (si activas el registro de contenido).\n",
    "\n",
    "Con esta informaci√≥n, podremos diagnosticar problemas y optimizar el rendimiento de nuestros modelos.\n",
    "\n",
    "Mostraremos c√≥mo configurar:\n",
    "1. **Azure Monitor** instrumentation with Application Insights.\n",
    "2. **Viewing** your traces in Azure AI Foundry's portal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767143a",
   "metadata": {},
   "source": [
    "### 4.1 Habilitar OpenTelemetry para Azure AI Inference\n",
    "  \n",
    "Establecemos variables de entorno para asegurar:\n",
    "1. **Prompt content** se captura (optional!)\n",
    "2. El **Azure SDK** utiliza OpenTelemetry como implementaci√≥n de trazabilidad.\n",
    "3. Llamamos a `AIInferenceInstrumentor().instrument()` para parchear y habilitar la instrumentaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef06776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Azure AI Inference instrumentation enabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.inference.tracing import AIInferenceInstrumentor\n",
    "\n",
    "# (Optional) capture prompt & completion contents in traces\n",
    "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"  # or 'false'\n",
    "\n",
    "# Let the Azure SDK know we want to use OpenTelemetry\n",
    "os.environ[\"AZURE_SDK_TRACING_IMPLEMENTATION\"] = \"opentelemetry\"\n",
    "\n",
    "# Instrument the Azure AI Inference client library\n",
    "AIInferenceInstrumentor().instrument()\n",
    "print(\"‚úÖ Azure AI Inference instrumentation enabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c0fdd4",
   "metadata": {},
   "source": [
    "Ahora configuraremos el tracing a **Application Insights**, que reenviar√° tus logs a la p√°gina de **Azure AI Foundry** **Tracing**.\n",
    "\n",
    "**Steps**:\n",
    "1. En AI Foundry, ve a la pesta√±a **Tracing** de tu proyecto, y asocia (o crea) un recurso de **Application Insights**.\n",
    "2. En el c√≥digo, llama a `project_client.telemetry.get_connection_string()` para obtener la clave de instrumentaci√≥n.\n",
    "3. Usa `azure.monitor.opentelemetry.configure_azure_monitor(...)` con esa conexi√≥n.\n",
    "4. Realiza una llamada de inferencia -> los logs aparecer√°n en el portal de Foundry (y en Azure Monitor).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552014a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Found App Insights connection string, configuring...\n",
      "\n",
      "ü§ñ Response (logged to App Insights):\n",
      "Absolutely! Here are some easy at-home cardio exercises to get your heart rate up and improve your cardiovascular fitness:\n",
      "\n",
      "1. **Jumping Jacks**: A great full-body workout that also improves coordination.\n",
      "\n",
      "2. **High Knees**: Run in place while lifting your knees as high as possible. This is excellent for the lower body and core.\n",
      "\n",
      "3. **Burpees**: A bit more intense, but they combine a squat, push-up, and jump for a full-body workout.\n",
      "\n",
      "4. **Mountain Climbers**: Start in a plank position and alternate bringing your knees towards your chest. This works your core and shoulders.\n",
      "\n",
      "5. **Skipping rope**: Simple, effective, and fun. It requires a jump rope but provides an excellent cardio workout.\n",
      "\n",
      "6. **Dancing**: Put on your favorite music and dance around your living room. It‚Äôs fun and a great way to get your heart rate up.\n",
      "\n",
      "7. **Shadow Boxing**: No equipment needed. Just throw punches in the air and incorporate some footwork to keep moving.\n",
      "\n",
      "8. **Step-Ups**: Use a sturdy chair or bench. Step up and down to mimic stair climbing.\n",
      "\n",
      "9. **Jump Squats**: Do a squat and then jump as high as you can when coming up. This adds a cardio element to a lower-body strength exercise.\n",
      "\n",
      "10. **Jogging or Marching in Place**: Simply jog or march without moving forward for a less intense option.\n",
      "\n",
      "11. **Kickboxing**: Follow along with a video or throw some kicks and punches in the air to get your blood pumping.\n",
      "\n",
      "Remember to start with a warm-up to get your muscles ready and finish with a cool-down to help with recovery. Adjust the intensity to your fitness level and enjoy your workout!\n"
     ]
    }
   ],
   "source": [
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from azure.ai.inference.models import UserMessage\n",
    "\n",
    "app_insights_conn_str = project_client.telemetry.get_connection_string()\n",
    "if app_insights_conn_str:\n",
    "    print(\"üîß Found App Insights connection string, configuring...\")\n",
    "    configure_azure_monitor(connection_string=app_insights_conn_str)\n",
    "    # Optionally add more instrumentation (for openai or langchain):\n",
    "    project_client.telemetry.enable()\n",
    "\n",
    "    # Let's do a test call that logs to AI Foundry's Tracing page\n",
    "    try:\n",
    "        with project_client.inference.get_chat_completions_client() as client:\n",
    "            prompt_msg = \"Any easy at-home cardio exercise recommendations?\"\n",
    "            response = client.complete(\n",
    "                model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
    "                messages=[UserMessage(content=prompt_msg)],\n",
    "            )\n",
    "            print(\"\\nü§ñ Response (logged to App Insights):\")\n",
    "            print(response.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Chat completions with Azure Monitor example failed:\", e)\n",
    "else:\n",
    "    print(\"No Application Insights connection string is configured in this project.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4991833",
   "metadata": {},
   "source": [
    "### 4.3 Visualizaci√≥n de Trazas en Azure AI Foundry\n",
    "Despu√©s de ejecutar el c√≥digo anterior:\n",
    "1. Ve a tu proyecto de AI Foundry.\n",
    "2. Haz clic en **Tracing** en la barra lateral.\n",
    "3. Deber√≠as ver los registros (logs) de tus llamadas.\n",
    "4. Filtra, expande o explora los detalles seg√∫n lo necesites.\n",
    "\n",
    "Adem√°s, si deseas paneles de control m√°s avanzados, puedes abrir tu recurso de **Application Insights** desde Foundry. En el portal de App Insights obtendr√°s otras funciones como detalles de transacciones de extremo a extremo, registros de consultas, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dbb932",
   "metadata": {},
   "source": [
    "# 5. Agent-based Example\n",
    "\n",
    "Ahora vamos a crear un **Health Resource Agent** que hace referencia a documentos de ejemplo sobre recetas o pautas, y luego demostramos:\n",
    "1. La creaci√≥n de un Agente con instrucciones.\n",
    "2. La creaci√≥n de un hilo de conversaci√≥n.\n",
    "3. La ejecuci√≥n de consultas en m√∫ltiples pasos con **observability** habilitada.\n",
    "4. Opcionalmente, la limpieza de recursos al final.\n",
    "\n",
    "> El enfoque basado en agentes es √∫til cuando deseas flujos de conversaci√≥n m√°s sofisticados o **tool usage** (como la b√∫squeda en archivos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ad934",
   "metadata": {},
   "source": [
    "## 5.1 Create Sample Files & Vector Store\n",
    "We'll create dummy `.md` files about recipes/guidelines, then push them into a **vector store** so our agent can do semantic search.\n",
    "\n",
    "(*This portion is a quick summary‚Äîsee [the other file-search tutorial] if you need more details.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e09113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Created sample resource files: recipes.md, guidelines.md\n",
      "‚úÖ Uploaded: recipes.md -> File ID: assistant-4FUBeBupfHfJRPTXerDZWn\n",
      "‚úÖ Uploaded: guidelines.md -> File ID: assistant-F84Yj13sDtAuVgNCCTkmMy\n",
      "‚ùå Error creating vector store: (None) Failed to create vector store.\n",
      "Code: None\n",
      "Message: Failed to create vector store.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import (\n",
    "    FileSearchTool,\n",
    "    FilePurpose,\n",
    "    MessageTextContent,\n",
    "    MessageRole,\n",
    ")\n",
    "\n",
    "\n",
    "def create_sample_files():\n",
    "    \"\"\"Create some local .md files with sample text.\"\"\"\n",
    "    recipes_md = \"\"\"# Base de Datos de Recetas Saludables\\n\\n\"\n",
    "        \"## Recetas sin Gluten\\n\"\n",
    "        \"1. Taz√≥n de Quinoa\\n\"\n",
    "        \"   - Ingredientes: quinoa, verduras, aceite de oliva\\n\"\n",
    "        \"   - Instrucciones: Cocer la quinoa, agregar verduras\\n\\n\"\n",
    "        \"2. Pasta de Arroz\\n\"\n",
    "        \"   - Ingredientes: pasta de arroz, verduras mixtas\\n\"\n",
    "        \"   - Instrucciones: Hervir la pasta, saltear las verduras\\n\\n\"\n",
    "        \"## Recetas para Diab√©ticos\\n\"\n",
    "        \"1. Salteado Bajo en Carbohidratos\\n\"\n",
    "        \"   - Ingredientes: pollo, verduras, salsa de tamari\\n\"\n",
    "        \"   - Instrucciones: Cocinar el pollo, agregar verduras\\n\\n\"\n",
    "        \"## Recetas Saludables para el Coraz√≥n\\n\"\n",
    "        \"1. Salm√≥n al Horno\\n\"\n",
    "        \"   - Ingredientes: salm√≥n, lim√≥n, hierbas\\n\"\n",
    "        \"   - Instrucciones: Sazonar el salm√≥n, hornear\\n\\n\"\n",
    "        \"2. Taz√≥n Mediterr√°neo\\n\"\n",
    "        \"   - Ingredientes: garbanzos, verduras, tahini\\n\"\n",
    "        \"   - Instrucciones: Combinar ingredientes\\n\"\"\"\n",
    "\n",
    "    guidelines_md = \"\"\"# Pautas Alimentarias\n",
    "\n",
    "        ## Pautas Generales\n",
    "        - Consume una variedad de alimentos\n",
    "        - Controla el tama√±o de las porciones\n",
    "        - Mantente hidratado\n",
    "\n",
    "        ## Dietas Especiales\n",
    "        1. Dieta sin Gluten\n",
    "        - Evita el trigo, la cebada y el centeno\n",
    "        - Enf√≥cate en alimentos naturalmente sin gluten\n",
    "\n",
    "        2. Dieta para Diab√©ticos\n",
    "        - Monitorea la ingesta de carbohidratos\n",
    "        - Elige alimentos de bajo √≠ndice gluc√©mico\n",
    "\n",
    "        3. Dieta Saludable para el Coraz√≥n\n",
    "        - Limita las grasas saturadas\n",
    "        - Elige prote√≠nas magras\"\"\"\n",
    "\n",
    "    with open(\"recipes.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(recipes_md)\n",
    "    with open(\"guidelines.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(guidelines_md)\n",
    "\n",
    "    print(\"üìÑ Created sample resource files: recipes.md, guidelines.md\")\n",
    "    return [\"recipes.md\", \"guidelines.md\"]\n",
    "\n",
    "\n",
    "sample_files = create_sample_files()\n",
    "\n",
    "\n",
    "def create_vector_store(files, store_name=\"my_health_resources\"):\n",
    "    try:\n",
    "        uploaded_ids = []\n",
    "        for fp in files:\n",
    "            upl = project_client.agents.upload_file_and_poll(\n",
    "                file_path=fp, purpose=FilePurpose.AGENTS  # Add FilePurpose.AGENTS here\n",
    "            )\n",
    "            uploaded_ids.append(upl.id)\n",
    "            print(f\"‚úÖ Uploaded: {fp} -> File ID: {upl.id}\")\n",
    "\n",
    "        # Create vector store from these file IDs\n",
    "        vs = project_client.agents.create_vector_store_and_poll(\n",
    "            file_ids=uploaded_ids, name=store_name\n",
    "        )\n",
    "        print(f\"üéâ Created vector store '{store_name}', ID: {vs.id}\")\n",
    "        return vs, uploaded_ids\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating vector store: {e}\")\n",
    "        return None, []\n",
    "\n",
    "\n",
    "vector_store, file_ids = None, []\n",
    "if sample_files:\n",
    "    vector_store, file_ids = create_vector_store(\n",
    "        sample_files, store_name=\"health_resources_example\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145eb186",
   "metadata": {},
   "source": [
    "## 5.2 Create a Health Resource Agent\n",
    "\n",
    "Crearemos un **FileSearchTool** que haga referencia al vector store, luego crearemos un agente con instrucciones de que debe:\n",
    "\n",
    "1. Proporcionar descargos de responsabilidad.\n",
    "2. Ofrecer consejos generales sobre nutrici√≥n o recetas.\n",
    "3. Citar fuentes cuando sea posible.\n",
    "4. Fomentar la consulta con profesionales para obtener asesoramiento m√©dico m√°s completo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f604175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import FileSearchTool, FilePurpose\n",
    "from azure.ai.projects.models import ConnectionType, MessageTextContent, MessageRole\n",
    "\n",
    "\n",
    "def create_health_agent(vs_id):\n",
    "    try:\n",
    "        # The tool references our vector store so the agent can search it\n",
    "        file_search_tool = FileSearchTool(vector_store_ids=[vs_id])\n",
    "\n",
    "        instructions = \"\"\"\n",
    "            Eres un asesor de recursos de salud con acceso a archivos de recetas y gu√≠as diet√©ticas.\n",
    "            T√∫:\n",
    "            1. Siempre presenta exenciones de responsabilidad (no eres un profesional m√©dico)\n",
    "            2. Proporciona referencias a archivos cuando sea posible.\n",
    "            3. Enf√≥cate en consejos generales de nutrici√≥n o recetas.\n",
    "            4. Fomenta la consulta con profesionales para obtener un asesoramiento m√°s detallado.\n",
    "        \"\"\"\n",
    "\n",
    "        agent = project_client.agents.create_agent(\n",
    "            model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
    "            name=\"health-search-agent\",\n",
    "            instructions=instructions,\n",
    "            tools=file_search_tool.definitions,\n",
    "            tool_resources=file_search_tool.resources,\n",
    "        )\n",
    "        print(f\"üéâ Created agent '{agent.name}' with ID: {agent.id}\")\n",
    "        return agent\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating health agent: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "health_agent = None\n",
    "if vector_store:\n",
    "    health_agent = create_health_agent(vector_store.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6995a6",
   "metadata": {},
   "source": [
    "## 5.3 Using the Agent\n",
    "Vamos a crear un n**thread** y preguntarle al agente algunas preguntas. Nos apoyaremos en la configuraci√≥n de **observability** que ya establecimos para que cada paso se rastree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e5b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thread():\n",
    "    try:\n",
    "        thread = project_client.agents.create_thread()\n",
    "        print(f\"üìù Created new thread, ID: {thread.id}\")\n",
    "        return thread\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not create thread: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def ask_question(thread_id, agent_id, user_question):\n",
    "    try:\n",
    "        # 1) Add user message\n",
    "        msg = project_client.agents.create_message(\n",
    "            thread_id=thread_id, role=\"user\", content=user_question\n",
    "        )\n",
    "        print(f\"User asked: '{user_question}'\")\n",
    "        # 2) Create & process a run\n",
    "        run = project_client.agents.create_and_process_run(\n",
    "            thread_id=thread_id, agent_id=agent_id\n",
    "        )\n",
    "        print(f\"Run finished with status: {run.status}\")\n",
    "        if run.last_error:\n",
    "            print(\"Error details:\", run.last_error)\n",
    "        return run\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error asking question: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if health_agent:\n",
    "    thread = create_thread()\n",
    "    if thread:\n",
    "        # Let's ask a few sample questions\n",
    "        queries = [\n",
    "            \"¬øPodr√≠as sugerir una receta de almuerzo sin gluten?\",\n",
    "            \"Mu√©strame algunas ideas de comidas saludables para el coraz√≥n.\",\n",
    "            \"¬øQu√© pautas tienes para alguien con diabetes?\",\n",
    "        ]\n",
    "        for q in queries:\n",
    "            ask_question(thread.id, health_agent.id, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c61d8d",
   "metadata": {},
   "source": [
    "### 5.3.1 Viewing the conversation\n",
    "We can retrieve the conversation messages to see how the agent responded, check if it cited file passages, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c57935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_thread(thread_id):\n",
    "    try:\n",
    "        messages = project_client.agents.list_messages(thread_id=thread_id)\n",
    "        print(\"\\nüó£Ô∏è Conversation:\")\n",
    "        for m in reversed(messages.data):\n",
    "            if m.content:\n",
    "                last_content = m.content[-1]\n",
    "                if hasattr(last_content, \"text\"):\n",
    "                    print(f\"[{m.role.upper()}]: {last_content.text.value}\\n\")\n",
    "\n",
    "        print(\"\\nüìé Checking for citations...\")\n",
    "        for c in messages.file_citation_annotations:\n",
    "            print(\n",
    "                f\"- Citation snippet: '{c.text}' from file ID: {c.file_citation['file_id']}\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not display thread: {e}\")\n",
    "\n",
    "\n",
    "# If we created a thread above, let's read it\n",
    "if health_agent and thread:\n",
    "    display_thread(thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7420c39",
   "metadata": {},
   "source": [
    "# 6. Cleanup\n",
    "If desired, we can remove the vector store, files, and agent to keep things tidy. (In a real solution, you might keep them around.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f473cddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Deleted vector store.\n",
      "üóëÔ∏è Deleted uploaded files.\n",
      "üóëÔ∏è Deleted health agent.\n",
      "üóëÔ∏è Deleted local sample files.\n"
     ]
    }
   ],
   "source": [
    "def cleanup_resources():\n",
    "    try:\n",
    "        if \"vector_store\" in globals() and vector_store:\n",
    "            project_client.agents.delete_vector_store(vector_store.id)\n",
    "            print(\"üóëÔ∏è Deleted vector store.\")\n",
    "\n",
    "        if \"file_ids\" in globals() and file_ids:\n",
    "            for fid in file_ids:\n",
    "                project_client.agents.delete_file(fid)\n",
    "            print(\"üóëÔ∏è Deleted uploaded files.\")\n",
    "\n",
    "        if \"health_agent\" in globals() and health_agent:\n",
    "            project_client.agents.delete_agent(health_agent.id)\n",
    "            print(\"üóëÔ∏è Deleted health agent.\")\n",
    "\n",
    "        if \"sample_files\" in globals() and sample_files:\n",
    "            for sf in sample_files:\n",
    "                if os.path.exists(sf):\n",
    "                    os.remove(sf)\n",
    "            print(\"üóëÔ∏è Deleted local sample files.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error cleaning up: {e}\")\n",
    "\n",
    "\n",
    "cleanup_resources()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  },
  "name": "Observability_and_Tracing_Comprehensive"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
