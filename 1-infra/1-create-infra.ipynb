{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ \u001b[1;32mNotebook initialized\u001b[0m ‚åö 08:10:39.093598 \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "\n",
    "sys.path.insert(1, \"../shared\")  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "\n",
    "deployment_name = \"ai-foundry\"\n",
    "resource_group_name = (\n",
    "    f\"lab-{deployment_name}\"  # change the name to match your naming convention\n",
    ")\n",
    "resource_group_location = (\n",
    "    \"eastus\"  # all the resources will be deployed in this location\n",
    ")\n",
    "\n",
    "build = 0\n",
    "\n",
    "# https://learn.microsoft.com/en-us/azure/ai-foundry/model-inference/concepts/models\n",
    "models_config = [\n",
    "    {\n",
    "        \"name\": \"DeepSeek-R1\",\n",
    "        \"publisher\": \"DeepSeek\",\n",
    "        \"version\": \"1\",\n",
    "        \"sku\": \"GlobalStandard\",\n",
    "        \"capacity\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Phi-4\",\n",
    "        \"publisher\": \"Microsoft\",\n",
    "        \"version\": \"3\",\n",
    "        \"sku\": \"GlobalStandard\",\n",
    "        \"capacity\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"gpt-4o\",\n",
    "        \"publisher\": \"OpenAI\",\n",
    "        \"version\": \"2024-05-13\",\n",
    "        \"sku\": \"GlobalStandard\",\n",
    "        \"capacity\": 100,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"text-embedding-3-large\",\n",
    "        \"publisher\": \"OpenAI\",\n",
    "        \"version\": \"1\",\n",
    "        \"sku\": \"Standard\",\n",
    "        \"capacity\": 1,\n",
    "    },\n",
    "]\n",
    "\n",
    "searchservice_sku = \"standard\"\n",
    "weather_mcp_server_image = \"weather-mcp-server\"\n",
    "weather_mcp_server_src = \"./src/weather/mcp-server\"\n",
    "\n",
    "principalId = \"\"\n",
    "if not principalId:\n",
    "    principalId = !az ad signed-in-user show --query id -o tsv\n",
    "    principalId = principalId[0]\n",
    "\n",
    "utils.print_ok(\"Notebook initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account show \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved az account\u001b[0m ‚åö 08:10:43.510425 [0m:1s]\n",
      "üëâüèΩ \u001b[1;34mCurrent user: pablocastao@microsoft.com\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mTenant ID: 16b3c013-d300-468d-ac64-7eda0820b6d3\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription ID: 06d043e2-5a2e-46bf-bf48-fffee525f377\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\n",
    "    \"az account show\", \"Retrieved az account\", \"Failed to get the current az account\"\n",
    ")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data[\"user\"][\"name\"]\n",
    "    tenant_id = output.json_data[\"tenantId\"]\n",
    "    subscription_id = output.json_data[\"id\"]\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az group show --name lab-ai-foundry \u001b[0m\n",
      "üëâüèΩ \u001b[1;34mResource group lab-ai-foundry does not yet exist. Creating the resource group now...\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az group create --name lab-ai-foundry --location eastus --tags source=ai-gateway \u001b[0m\n",
      "‚úÖ \u001b[1;32mResource group 'lab-ai-foundry' created\u001b[0m ‚åö 08:10:58.205257 [0m:4s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group create --name ai-foundry --resource-group lab-ai-foundry --template-file main.bicep --parameters params.json \u001b[0m\n",
      "‚úÖ \u001b[1;32mDeployment 'ai-foundry' succeeded\u001b[0m ‚åö 08:21:59.605398 [11m:1s]\n"
     ]
    }
   ],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"modelsConfig\": {\"value\": models_config},\n",
    "        \"principalId\": {\"value\": principalId},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open(\"params.json\", \"w\") as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(\n",
    "    f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\",\n",
    "    f\"Deployment '{deployment_name}' failed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group show --name ai-foundry -g lab-ai-foundry \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved deployment: ai-foundry\u001b[0m ‚åö 08:22:42.506217 [0m:2s]\n",
      "üëâüèΩ \u001b[1;34mProject Connection String: eastus.api.azureml.ms;06d043e2-5a2e-46bf-bf48-fffee525f377;lab-ai-foundry;project-demo-yais\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mApplication Insights Name: agent-appinsights-yais\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mContainer Registry Name: agentcontainerregistryyais\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mWeather Container App Resource Name: aca-weather-yais\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mWeather Container App URL: aca-weather-yais.grayrock-a41b8358.eastus.azurecontainerapps.io\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mBing Connection Name: hub-demo-yais-connection-BingSearch\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mModel Deployment Name: gpt-4o\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(\n",
    "    f\"az deployment group show --name {deployment_name} -g {resource_group_name}\",\n",
    "    f\"Retrieved deployment: {deployment_name}\",\n",
    "    f\"Failed to retrieve deployment: {deployment_name}\",\n",
    ")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    project = utils.get_deployment_output(\n",
    "        output, \"projectConnectionString\", \"Project Connection String\"\n",
    "    )\n",
    "    app_insights_name = utils.get_deployment_output(\n",
    "        output, \"applicationInsightsName\", \"Application Insights Name\"\n",
    "    )\n",
    "    container_registry_name = utils.get_deployment_output(\n",
    "        output, \"containerRegistryName\", \"Container Registry Name\"\n",
    "    )\n",
    "    weather_containerapp_resource_name = utils.get_deployment_output(\n",
    "        output,\n",
    "        \"weatherMCPServerContainerAppResourceName\",\n",
    "        \"Weather Container App Resource Name\",\n",
    "    )\n",
    "    weather_containerapp_url = utils.get_deployment_output(\n",
    "        output, \"weatherMCPServerContainerAppFQDN\", \"Weather Container App URL\"\n",
    "    )\n",
    "    bingConnectionName = utils.get_deployment_output(\n",
    "        output, \"bingConnectionName\", \"Bing Connection Name\"\n",
    "    )\n",
    "    model_deployment_name = utils.get_deployment_output(\n",
    "        output, \"modelDeploymentName\", \"Model Deployment Name\"\n",
    "    )\n",
    "    # Write the project and outputs to an .env file\n",
    "    with open(\"../.env\", \"w\") as env_file:\n",
    "        env_file.write(f\"PROJECT_CONNECTION_STRING='{project}'\\n\")\n",
    "        env_file.write(f\"APPLICATION_INSIGHTS_NAME='{app_insights_name}'\\n\")\n",
    "        env_file.write(f\"CONTAINER_REGISTRY_NAME='{container_registry_name}'\\n\")\n",
    "        env_file.write(\n",
    "            f\"WEATHER_CONTAINERAPP_RESOURCE_NAME='{weather_containerapp_resource_name}'\\n\"\n",
    "        )\n",
    "        env_file.write(f\"WEATHER_CONTAINERAPP_URL='{weather_containerapp_url}'\\n\")\n",
    "        env_file.write(f\"BING_CONNECTION_NAME='{bingConnectionName}'\\n\")\n",
    "        env_file.write(f\"MODEL_DEPLOYMENT_NAME='{model_deployment_name}'\\n\")\n",
    "        env_file.write(f\"AOAI_API_VERSION='2024-12-01-preview'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Build and deploy the MCP Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az acr build --image weather-mcp-server:v0.1 --resource-group lab-ai-foundry --registry agentcontainerregistryyais --file ./src/weather/mcp-server/Dockerfile ./src/weather/mcp-server/. --no-logs \u001b[0m\n",
      "‚úÖ \u001b[1;32mWeather MCP Server image was successfully built\u001b[0m ‚åö 08:23:54.805723 [1m:7s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az containerapp update -n aca-weather-yais -g lab-ai-foundry --image \"agentcontainerregistryyais.azurecr.io/weather-mcp-server:v0.1\" \u001b[0m\n",
      "‚úÖ \u001b[1;32mWeather MCP Server deployment succeeded\u001b[0m ‚åö 08:24:16.485152 [0m:21s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.Output at 0x2082a924d50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build = build + 1  # increment the build number\n",
    "\n",
    "utils.run(\n",
    "    f\"az acr build --image {weather_mcp_server_image}:v0.{build} --resource-group {resource_group_name} --registry {container_registry_name} --file {weather_mcp_server_src}/Dockerfile {weather_mcp_server_src}/. --no-logs\",\n",
    "    \"Weather MCP Server image was successfully built\",\n",
    "    \"Failed to build the Weather MCP Server image\",\n",
    ")\n",
    "utils.run(\n",
    "    f'az containerapp update -n {weather_containerapp_resource_name} -g {resource_group_name} --image \"{container_registry_name}.azurecr.io/{weather_mcp_server_image}:v0.{build}\"',\n",
    "    \"Weather MCP Server deployment succeeded\",\n",
    "    \"Weather MCP Server deployment failed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
